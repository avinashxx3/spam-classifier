{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93993acd",
   "metadata": {},
   "source": [
    "# Assignment: Classification\n",
    "\n",
    "Classification refers to categorizing the given data into classes. For example,\n",
    "- Given an image of hand-written character, identifying the character (multi-class classification)\n",
    "- Given an image, annotating it with all the objects present in the image (multi-label classification)\n",
    "- Classifying an email as spam or non-spam (binary classification)\n",
    "- Classifying a tumor as benign or malignant and so on\n",
    "\n",
    "In this assignment, we will be building a classifier to classify emails as spam or non-spam. We will be using the Kaggle dataset [Spam or Not Spam Dataset](https://www.kaggle.com/datasets/ozlerhakan/spam-or-not-spam-dataset?resource=download) for this task. \n",
    "\n",
    "**Note**: You cannot load any libraries other than the mentioned ones.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df69dbc",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "The first step in every machine learning algorithm is to process the raw data in some meaningful representations. We will be using the [Bag-of-Words](https://towardsdatascience.com/a-simple-explanation-of-the-bag-of-words-model-b88fc4f4971) representation to process the text. It comprises of following steps:\n",
    "\n",
    "- Process emails line-by-line to extract all the words.\n",
    "- Replace extracted words by their stem (root) word. This is known as stemming and lematization.\n",
    "- Remove stop words like and, or, is, am, and so on.\n",
    "- Assign a unique index to each word. This forms the vocabulary.\n",
    "- Represent each email as a binary vector of length equal to the size of the vocabulary such that the $i^{th}$ element of the vector is 1 iff the $i^th$ word is present in the email.\n",
    "\n",
    "Here we provide you with the function signature along with the expected functionality. You are expected to complete them accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851dc5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes an email as an argument\n",
    "# read email line-by-line and extract all the words\n",
    "# return list of exracted words\n",
    "def read_email(email):\n",
    "    words = email.split(\" \")\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of words as an argument\n",
    "# replace each word by their stem word\n",
    "# return list of stem words\n",
    "def stemming(list_of_words):\n",
    "    porter = PorterStemmer()\n",
    "    stem_words = [porter.stem(word) for word in list_of_words]\n",
    "    return stem_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac215dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of stem-words as an argument\n",
    "# remove stop words\n",
    "# return list of stem words after removing stop words\n",
    "def remove_stop_words(list_of_stem_words):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stem_no_stop_words = [w for w in list_of_stem_words if not w.lower() in stop_words]\n",
    "    return stem_no_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of stem-words as an argument\n",
    "# add new words to the vocabulary and assign a unique index to them\n",
    "# returns new vocabulary\n",
    "def build_vocabulary(list_of_stem_words):\n",
    "    vocabulary = set()\n",
    "    for word_list in list_of_stem_words:\n",
    "        for word in word_list:\n",
    "            vocabulary.add(word)\n",
    "    vocab = [word for word in vocabulary]\n",
    "    vocab.pop(0)\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23791737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of stem-words and vocabulary as an argument\n",
    "# returns bow representation\n",
    "def get_bow(list_of_stem_words, vocab):\n",
    "    email_bow = []\n",
    "\n",
    "    for data_list in list_of_stem_words:\n",
    "        dict = {}\n",
    "        for word in vocab:\n",
    "            dict.update({word:0})\n",
    "        for word in vocab:\n",
    "            if word in data_list:\n",
    "                dict[word] += 1\n",
    "        email_bow.append(dict)\n",
    "\n",
    "    return email_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfbc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the entire list_of_stem_words\n",
    "# convert emails to bow and maintain their labels\n",
    "# call function text_to_bow()\n",
    "def read_data():\n",
    "    results = []\n",
    "    with open('spam_or_not_spam.csv', 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "                words = line.split(',')\n",
    "                results.append([words[0], words[1][0][0]])\n",
    "    spam_or_not_spam = results\n",
    "    spam_or_not_spam.pop(0)\n",
    "    list_of_stem_words = []\n",
    "    data = []\n",
    "    for mail in spam_or_not_spam:\n",
    "        list_of_stem_words.append(remove_stop_words(stemming(read_email(mail[0]))))\n",
    "    vocabulary = build_vocabulary(list_of_stem_words)\n",
    "    vocabulary.pop(0)\n",
    "    bows = get_bow(list_of_stem_words, vocabulary)\n",
    "    for i in range(0,len(spam_or_not_spam)):\n",
    "        data.append([bows[i], int(spam_or_not_spam[i][1])])\n",
    "    \n",
    "    return data,vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9a549",
   "metadata": {},
   "source": [
    "### Data Visualization\n",
    "Let's understand the data distribution\n",
    "- Visualize the frequency of word-occurence in all the emails(spam + non-spam)\n",
    "- Visualize the freuency of word-occurence for spam and non-spam emails separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35949bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize data distribution\n",
    "def data_vis(data, vocabulary):\n",
    "    dict_non_spam = {}\n",
    "    dict_spam = {}\n",
    "    dict_all = {}\n",
    "    for word in vocabulary:\n",
    "            dict_all.update({word:0})\n",
    "            dict_non_spam.update({word:0})\n",
    "            dict_spam.update({word:0})\n",
    "\n",
    "    for ind_data in data:\n",
    "        for key, value in ind_data[0].items():\n",
    "            dict_all[key] += int(value)\n",
    "            if ind_data[1] == 0:\n",
    "                dict_non_spam[key] += int(value)\n",
    "            else:\n",
    "                dict_spam[key] += int(value)\n",
    "    \n",
    "    lists_all = sorted(dict_all.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    x_axis, y_axis = zip(*lists_all)\n",
    "    plt.bar(x_axis, y_axis)\n",
    "    plt.title(\"Spam + Non-Spam Plot\")\n",
    "    plt.ylim(top = y_axis[0]+10)\n",
    "    plt.show()\n",
    "    lists_non_spam = sorted(dict_non_spam.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    x_axis, y_axis = zip(*lists_non_spam)\n",
    "    plt.bar(x_axis, y_axis)\n",
    "    plt.title(\"Non-Spam Plot\")\n",
    "    plt.ylim(top = y_axis[0]+10)\n",
    "    plt.show()\n",
    "    lists_spam = sorted(dict_spam.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    x_axis, y_axis = zip(*lists_spam)\n",
    "    plt.bar(x_axis, y_axis)\n",
    "    plt.ylim(top = y_axis[0]+10)\n",
    "    plt.title(\"Spam\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
